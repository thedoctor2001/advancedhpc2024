{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37jLsD2RG0C2",
        "outputId": "7cab56b9-8d6a-4715-e19b-2f42766e4abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numba"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numba as nb"
      ],
      "metadata": {
        "id": "mcyOqjnQJZDI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "\n",
        "devices = cuda.detect()\n",
        "\n",
        "device = cuda.select_device(0)\n",
        "\n",
        "device_name = device.name\n",
        "multiprocessor_count = device.MULTIPROCESSOR_COUNT\n",
        "core_count = multiprocessor_count * 128\n",
        "\n",
        "free_mem, total_mem = cuda.current_context().get_memory_info()\n",
        "memory_size_gb = total_mem / (1024 ** 3)\n",
        "\n",
        "print(f\"Device Name: {device_name}\")\n",
        "print(f\"Multiprocessor Count: {multiprocessor_count}\")\n",
        "print(f\"Estimated Core Count: {core_count}\")\n",
        "print(f\"Total Memory Size: {memory_size_gb:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA3N5XhIJt52",
        "outputId": "50339219-f55d-4d01-fcff-54a79dab312b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0             b'Tesla T4'                              [SUPPORTED]\n",
            "                      Compute Capability: 7.5\n",
            "                           PCI Device ID: 4\n",
            "                              PCI Bus ID: 0\n",
            "                                    UUID: GPU-1a27adec-5b74-23c7-1403-69d80811c0f1\n",
            "                                Watchdog: Disabled\n",
            "             FP32/FP64 Performance Ratio: 32\n",
            "Summary:\n",
            "\t1/1 devices are supported\n",
            "Device Name: b'Tesla T4'\n",
            "Multiprocessor Count: 40\n",
            "Estimated Core Count: 5120\n",
            "Total Memory Size: 14.75 GB\n"
          ]
        }
      ]
    }
  ]
}